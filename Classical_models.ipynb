{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.89 seconds)\n",
      "Writing emoji data to /home/punyajoy/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    }
   ],
   "source": [
    "from laserembeddings import Laser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "import numpy as np\n",
    "parent_path='../Data/New_Data_15-06-2020/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4782\n"
     ]
    }
   ],
   "source": [
    "annotated_df=pd.read_pickle(parent_path+'Fearspeech_data_final.pkl')\n",
    "# annotated_df=remove_duplicates_within(annotated_df)\n",
    "print(len(annotated_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4782/4782 [00:37<00:00, 128.58it/s]\n"
     ]
    }
   ],
   "source": [
    "list_text = []\n",
    "lang_text = []\n",
    "for index,row in tqdm(annotated_df.iterrows(),total=len(annotated_df)):\n",
    "    if len(row['message_text'])>4000:\n",
    "        string=row['message_text'][0:2000]+row['message_text'][-2000:]\n",
    "        list_text.append(demoji.replace(string,repl=\"\"))\n",
    "    else:\n",
    "        list_text.append(demoji.replace(row[\"message_text\"],repl=\"\"))\n",
    "    lang_text.append(row[\"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [04:45<00:00,  2.31s/it]\n"
     ]
    }
   ],
   "source": [
    "laser = Laser()\n",
    "\n",
    "embed_list=[]\n",
    "\n",
    "length_given=len(list_text)\n",
    "batch_size=64\n",
    "for i in tqdm(range(0,length_given,batch_size)):\n",
    "    if(i+batch_size<=length_given):\n",
    "        temp_text=list_text[i:i+batch_size]\n",
    "        temp_lang=lang_text[i:i+batch_size]\n",
    "    else:\n",
    "        temp_text=list_text[i:length_given]\n",
    "        temp_lang=lang_text[i:length_given]\n",
    "    embeddings = laser.embed_sentences(temp_text,lang=temp_lang)  # lang is only used for tokenization\n",
    "    embed_list+=list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.array(embed_list)\n",
    "y_0 = np.array(annotated_df['one_fear_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [446 447 448 449 450] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567460317460317, 1: 2.0949367088607596}\n",
      "TRAIN: [0 1 2 3 4] TEST: [446 447 448 449 450]\n",
      "{0: 0.6567460317460317, 1: 2.0949367088607596}\n",
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1332 1334 1335 1336 1337]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2251 2252 2254 2255 2256]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3281 3282 3284 3285 3287]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [4302 4305 4306 4307 4308]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n"
     ]
    }
   ],
   "source": [
    "acc=[]\n",
    "macro_f1=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "prob=[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state= 2020)\n",
    "\n",
    "for train_index, test_index in skf.split(X_0, y_0):\n",
    "    print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "    X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "    y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "    class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "    print(class_weights)\n",
    "    classifier= LogisticRegression(class_weight=class_weights)\n",
    "    #classifier=SVC(class_weight=class_weights,kernel='rbf',probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred=classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    prec.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    prob.append(classifier.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For SVC (with rbf kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.68 (+/- 0.11)\n",
      "Macro F1: 0.63 (+/- 0.08)\n",
      "Precision for +ve class: 0.40 (+/- 0.14)\n",
      "Recall for +ve class: 0.64 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For logisitic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.67 (+/- 0.12)\n",
      "Macro F1: 0.62 (+/- 0.10)\n",
      "Precision for +ve class: 0.40 (+/- 0.15)\n",
      "Recall for +ve class: 0.67 (+/- 0.11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4782/4782 [00:57<00:00, 83.43it/s] \n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import *\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "list_sents=[preprocess_sent(ele,params={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': True}) for ele in tqdm(annotated_df['message_text'],total=len(annotated_df))]\n",
    "X_0 = np.array(list_sents,dtype='object')\n",
    "y_0 = np.array(annotated_df['one_fear_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [446 447 448 449 450] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567460317460317, 1: 2.0949367088607596}\n",
      "TRAIN: [0 1 2 3 4] TEST: [446 447 448 449 450]\n",
      "{0: 0.6567460317460317, 1: 2.0949367088607596}\n",
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1332 1334 1335 1336 1337]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2251 2252 2254 2255 2256]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3281 3282 3284 3285 3287]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n",
      "TRAIN: [0 1 2 3 4] TEST: [4302 4305 4306 4307 4308]\n",
      "{0: 0.6568986568986569, 1: 2.093385214007782}\n"
     ]
    }
   ],
   "source": [
    "acc=[]\n",
    "macro_f1=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "prob=[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state= 2020)\n",
    "\n",
    "for train_index, test_index in skf.split(X_0, y_0):\n",
    "    print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "    X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "    y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "    class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "    \n",
    "    \n",
    "    print(class_weights)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "    model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=10)\n",
    "    X_train_embed = np.array([list(model.infer_vector(ele)) for ele in X_train])\n",
    "    X_test_embed = np.array([list(model.infer_vector(ele)) for ele in X_test])\n",
    "    #classifier= LogisticRegression(class_weight=class_weights,max_iter=500)\n",
    "    classifier=SVC(class_weight=class_weights,kernel='rbf',probability=True)\n",
    "    classifier.fit(X_train_embed, y_train)\n",
    "    y_pred=classifier.predict(X_test_embed)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    prec.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    prob.append(classifier.predict_proba(X_test_embed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76 (+/- 0.06)\n",
      "Macro F1: 0.70 (+/- 0.06)\n",
      "Precision for +ve class: 0.52 (+/- 0.14)\n",
      "Recall for +ve class: 0.60 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74 (+/- 0.08)\n",
      "Macro F1: 0.67 (+/- 0.07)\n",
      "Precision for +ve class: 0.47 (+/- 0.13)\n",
      "Recall for +ve class: 0.62 (+/- 0.14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.054082505, 0.09554306, -0.02666436, -0.04751123, -0.0072117187]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
