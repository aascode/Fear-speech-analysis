{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:07:16.300209Z",
     "start_time": "2020-09-26T09:07:16.126647Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "import numpy as np\n",
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix,make_scorer, f1_score, accuracy_score, recall_score, precision_score, roc_auc_score,classification_report, precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    \n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='macro'))\n",
    "    avg.append(accuracy_score(y_true, y_pred, normalize=True))\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support','accuracy']\n",
    "    list_all=list(metrics_summary)\n",
    "    list_all.append(cm.diagonal())\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list_all,\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-2] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_path='Data/'\n",
    "\n",
    "import json\n",
    "with open(parent_path+'fear_speech_data.json', 'r') as fp:\n",
    "    fear_speech_data=json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_text': '*प्रशासक समिति*✊🚩  ●●●●●●●●●●● ● ● ● 😎🚩 *आंतकवादी संगठनों का💣🔪 इस्लामिक नाम और उनका इस्लाम.....* *धर्म से जुड़ा हुआ अर्थ...* 🐖🐖🐖 *1.लश्करे तैयबा-फरिश्तो की सेना* *2.अल कायदा-अल्लाह का कायदा...* *3.जेश ए मोहम्द-मोहम्मद साहेब का दल...* *4.तहरिक ए तालिबान-पवित्र योद्धाओ का दल...* *5.हिजबुल मुजादिन-इस्लामी बलिदानियो का समूह...* *6.बोको हराम -पैगम्बर मुहम्मद की शिक्षा को फैलाने के लिए प्रतिबद्ध..* *सभी मुस्लमान अज्ञानि अल्लाह की बताई हुई रूहानी किताब क़ुरआन की बताई राह* *(पूरी दुनिया को इस्लाम बनाना)पर ही चल रहे है कोई ज्यादा बच👨\\u200d👨\\u200d👦* *पैदा करके तो कोई लव जिहाद👫 करके तो कोई काफ़िर(गेर मुसलमान)को मारकर..* *धरती पर आंतक🔫💣💣💣🔫फेला रहे है\\ufeff।।* 😡😡😡😎😡😡😡  *जय सनातन धर्म की*🚩🚩🚩  🙏🚩🇮🇳🔱🏹🐚🕉',\n",
       " 'translated_text': '* Administrator ✊ 🚩   Committee * ● ●●●●●●●●●● 🚩  😎  ● ● ● नाम 🔪  💣  * Islamic name of terrorist organizations and their meaning 🐖  🐖  🐖  in Islam… .. * Religion… * ... 1. * 1. Army of Lashkar-e-Taiba-Farishto * * 2. Al Qaeda-Qaeda of Allah ... * * 3. Team of Jesh-e-Mohammad-Mohammed Saheb ... * * 4. Tahrik-e-Taliban-Holy Warriors Party ... * * 5. Hijbul Mujadin-group of Islamic sacrifices ... * * 6. Boko Haram - Committed to spread the teachings of Prophet Muhammad .. * * All the Muslim ignorance told the Quran of Allah the 👨 👦   👨  spiritual book The path 👫  is going on * (making the whole world Islam), by creating 🔫  💣  💣  💣  🔫 😡 😡 😡 😡  😡   😎   😡    some 🚩 🚩  🙏 🇮 🔱 🐚 🕉   🏹   🇳   🚩   🚩   more children * * *, by creating some love jihad and by killing a kafir (Ger Muslim) .. * * Terror on Earth 💣💣💣🔫Fella is there. * 😡😡😡😎😡😡😡 * Jai of Sanatan Dharma * 🚩🚩🚩 🙏🚩🇮🇳🔱🏹🐚🕉  ',\n",
       " 'annotation_list': ['Fear speech', 'Fear speech', 'Normal'],\n",
       " 'propagation': [{'group_id': 9087,\n",
       "   'user_id': 229869,\n",
       "   'timestamp': 1538130086000},\n",
       "  {'group_id': 7, 'user_id': 215, 'timestamp': 1550186113000}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fear_speech_data['0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00b0ce0b4cc419987c1b50f4977c81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4782.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.preprocess import *\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "list_sents = []\n",
    "list_labels=[]\n",
    "for key in tqdm_notebook(fear_speech_data.keys(),total=len(fear_speech_data)):\n",
    "    element = fear_speech_data[key]\n",
    "    \n",
    "    count_fearspeech=element['annotation_list'].count('Fear speech')\n",
    "    count_normal=element['annotation_list'].count('Normal')\n",
    "    \n",
    "    if(count_fearspeech>count_normal):\n",
    "        one_fear_speech=1\n",
    "    else:\n",
    "        one_fear_speech=0\n",
    "    \n",
    "    text=preprocess_sent(element['message_text'],params={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': True})\n",
    "    list_sents.append(text)\n",
    "    list_labels.append(one_fear_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.array(list_sents,dtype='object')\n",
    "y_0 = np.array(list_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_run(model_name='lr'):\n",
    "    acc=[]\n",
    "    macro_f1=[]\n",
    "    prec=[]\n",
    "    recall=[]\n",
    "    prob=[]\n",
    "    auc_roc=[]\n",
    "    list_total_preds=[]\n",
    "    list_total_truth=[]\n",
    "    skf = StratifiedKFold(n_splits=5, random_state= 2020)\n",
    "\n",
    "    for train_index, test_index in skf.split(X_0, y_0):\n",
    "        print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "        X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "        y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "\n",
    "        class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "\n",
    "\n",
    "        print(class_weights)\n",
    "        ### Generate doc2vec vectors\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "        model = Doc2Vec(documents, vector_size=300, window=5, min_count=1, workers=10)\n",
    "        X_train_embed = np.array([list(model.infer_vector(ele)) for ele in X_train])\n",
    "        X_test_embed = np.array([list(model.infer_vector(ele)) for ele in X_test])\n",
    "        \n",
    "        if(model_name=='lr'):\n",
    "            classifier= LogisticRegression(class_weight='balanced',max_iter=500)\n",
    "        \n",
    "        elif(model_name=='svc'):\n",
    "            classifier=SVC(class_weight='balanced',kernel='rbf',probability=True)\n",
    "        \n",
    "        classifier.fit(X_train_embed, y_train)\n",
    "        y_pred=classifier.predict(X_test_embed)\n",
    "        y_pred_proba = classifier.predict_proba(X_test_embed)\n",
    "        acc.append(accuracy_score(y_test, y_pred))\n",
    "        macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "        auc_roc.append(roc_auc_score(y_test, y_pred_proba[:,1],average='macro'))\n",
    "        prec.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        prob.append(classifier.predict_proba(X_test_embed))\n",
    "        list_total_preds+=list(y_pred)\n",
    "        list_total_truth+=list(y_test)\n",
    "    return acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [870 872 873 874 875] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "Accuracy: 0.75 (+/- 0.07)\n",
      "Macro F1: 0.68 (+/- 0.06)\n",
      "Auc Roc F1: 0.77 (+/- 0.07)\n",
      "Precision for +ve class: 0.50 (+/- 0.16)\n",
      "Recall for +ve class: 0.60 (+/- 0.13)\n",
      "             precision    recall  f1-score  support  accuracy\n",
      "0             0.864512  0.801099  0.831598   3640.0  0.801099\n",
      "1             0.486160  0.599825  0.537044   1142.0  0.599825\n",
      "avg / total   0.675336  0.700462  0.684321   4782.0  0.753032\n"
     ]
    }
   ],
   "source": [
    "acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall=model_run(model_name='svc')\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Auc Roc F1: %0.2f (+/- %0.2f)\" % (np.mean(auc_roc), np.std(auc_roc) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))\n",
    "print(pandas_classification_report(list_total_truth, list_total_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [870 872 873 874 875] TEST: [0 1 2 3 4]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/punyajoy/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [0 1 2 3 4] TEST: [870 872 873 874 875]\n",
      "{0: 0.6567651098901099, 1: 2.0947426067907995}\n",
      "TRAIN: [0 1 2 3 4] TEST: [1771 1772 1773 1774 1775]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [2757 2758 2759 2761 2762]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "TRAIN: [0 1 2 3 4] TEST: [3792 3794 3796 3799 3801]\n",
      "{0: 0.6569368131868132, 1: 2.0929978118161925}\n",
      "Accuracy: 0.73 (+/- 0.08)\n",
      "Macro F1: 0.67 (+/- 0.07)\n",
      "Auc Roc: 0.76 (+/- 0.08)\n",
      "Precision for +ve class: 0.47 (+/- 0.15)\n",
      "Recall for +ve class: 0.60 (+/- 0.14)\n",
      "             precision    recall  f1-score  support  accuracy\n",
      "0             0.861543  0.776099  0.816592   3640.0  0.776099\n",
      "1             0.457751  0.602452  0.520227   1142.0  0.602452\n",
      "avg / total   0.659647  0.689275  0.668409   4782.0  0.734630\n"
     ]
    }
   ],
   "source": [
    "acc, macro_f1, prec, prob,auc_roc,list_total_preds,list_total_truth,prec,recall=model_run(model_name='lr')\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Auc Roc: %0.2f (+/- %0.2f)\" % (np.mean(auc_roc), np.std(auc_roc) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))\n",
    "print(pandas_classification_report(list_total_truth, list_total_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
