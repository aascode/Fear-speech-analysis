{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:07:16.300209Z",
     "start_time": "2020-09-26T09:07:16.126647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from laserembeddings import Laser\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook,tqdm\n",
    "#import demoji\n",
    "#demoji.download_codes()\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T09:04:13.211420Z",
     "start_time": "2020-09-26T09:03:46.752781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting laserembeddings\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ConnectTimeoutError(<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x7fe9c322c828>, 'Connection to 172.16.2.30 timed out. (connect timeout=15)')': /simple/laserembeddings/\u001b[0m\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T08:09:35.033572Z",
     "start_time": "2020-09-26T08:09:35.027686Z"
    }
   },
   "outputs": [],
   "source": [
    "parent_path='../Data/New_Data_15-06-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df=pd.read_pickle(parent_path+'Fearspeech_data_final.pkl')\n",
    "# annotated_df=remove_duplicates_within(annotated_df)\n",
    "print(len(annotated_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_text = []\n",
    "lang_text = []\n",
    "for index,row in tqdm(annotated_df.iterrows(),total=len(annotated_df)):\n",
    "    if len(row['message_text'])>4000:\n",
    "        string=row['message_text'][0:2000]+row['message_text'][-2000:]\n",
    "        list_text.append(demoji.replace(string,repl=\"\"))\n",
    "    else:\n",
    "        list_text.append(demoji.replace(row[\"message_text\"],repl=\"\"))\n",
    "    lang_text.append(row[\"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LASER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laser = Laser()\n",
    "\n",
    "embed_list=[]\n",
    "\n",
    "length_given=len(list_text)\n",
    "batch_size=64\n",
    "for i in tqdm(range(0,length_given,batch_size)):\n",
    "    if(i+batch_size<=length_given):\n",
    "        temp_text=list_text[i:i+batch_size]\n",
    "        temp_lang=lang_text[i:i+batch_size]\n",
    "    else:\n",
    "        temp_text=list_text[i:length_given]\n",
    "        temp_lang=lang_text[i:length_given]\n",
    "    embeddings = laser.embed_sentences(temp_text,lang=temp_lang)  # lang is only used for tokenization\n",
    "    embed_list+=list(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_0 = np.array(embed_list)\n",
    "y_0 = np.array(annotated_df['one_fear_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "macro_f1=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "prob=[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state= 2020)\n",
    "\n",
    "for train_index, test_index in skf.split(X_0, y_0):\n",
    "    print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "    X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "    y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "    class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "    print(class_weights)\n",
    "    classifier= LogisticRegression(class_weight=class_weights)\n",
    "    #classifier=SVC(class_weight=class_weights,kernel='rbf',probability=True)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred=classifier.predict(X_test)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    prec.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    prob.append(classifier.predict_proba(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For SVC (with rbf kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For logisitic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocess import *\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "list_sents=[preprocess_sent(ele,params={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': True}) for ele in tqdm(annotated_df['message_text'],total=len(annotated_df))]\n",
    "X_0 = np.array(list_sents,dtype='object')\n",
    "y_0 = np.array(annotated_df['one_fear_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "macro_f1=[]\n",
    "prec=[]\n",
    "recall=[]\n",
    "prob=[]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state= 2020)\n",
    "\n",
    "for train_index, test_index in skf.split(X_0, y_0):\n",
    "    print(\"TRAIN:\", train_index[0:5], \"TEST:\", test_index[0:5])\n",
    "    X_train, X_test = X_0[train_index], X_0[test_index]\n",
    "    y_train, y_test = y_0[train_index], y_0[test_index]\n",
    "    class_weights = dict(zip(np.unique(y_train), compute_class_weight(\"balanced\", np.unique(y_train),y_train)))\n",
    "    \n",
    "    \n",
    "    print(class_weights)\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "    model = Doc2Vec(documents, vector_size=100, window=5, min_count=1, workers=10)\n",
    "    X_train_embed = np.array([list(model.infer_vector(ele)) for ele in X_train])\n",
    "    X_test_embed = np.array([list(model.infer_vector(ele)) for ele in X_test])\n",
    "    #classifier= LogisticRegression(class_weight=class_weights,max_iter=500)\n",
    "    classifier=SVC(class_weight=class_weights,kernel='rbf',probability=True)\n",
    "    classifier.fit(X_train_embed, y_train)\n",
    "    y_pred=classifier.predict(X_test_embed)\n",
    "    acc.append(accuracy_score(y_test, y_pred))\n",
    "    macro_f1.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    prec.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    prob.append(classifier.predict_proba(X_test_embed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (np.mean(acc), np.std(acc) * 2))\n",
    "print(\"Macro F1: %0.2f (+/- %0.2f)\" % (np.mean(macro_f1), np.std(macro_f1) * 2))\n",
    "print(\"Precision for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(prec), np.std(prec) * 2))\n",
    "print(\"Recall for +ve class: %0.2f (+/- %0.2f)\" % (np.mean(recall), np.std(recall) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T08:10:17.217030Z",
     "start_time": "2020-09-26T08:09:38.207207Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4782/4782 [00:38<00:00, 124.63it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.preprocess import *\n",
    " \n",
    "\n",
    "annotated_df=pd.read_pickle(parent_path+'Fearspeech_data_final.pkl')\n",
    "params_preprocess={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': False}\n",
    "list_sents=[preprocess_doc(ele,params=params_preprocess) for ele in tqdm(annotated_df['message_text'],total=len(annotated_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T08:14:08.625664Z",
     "start_time": "2020-09-26T08:14:08.616331Z"
    }
   },
   "outputs": [],
   "source": [
    "length_sent=[]\n",
    "for sent in list_sents:\n",
    "    \n",
    "    length_sent.append(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T08:15:32.740878Z",
     "start_time": "2020-09-26T08:15:32.730908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(length_sent) > 80)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-26T08:14:25.569858Z",
     "start_time": "2020-09-26T08:14:25.556742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 10,\n",
       " 29,\n",
       " 2,\n",
       " 11,\n",
       " 25,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 15,\n",
       " 1,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 30,\n",
       " 24,\n",
       " 11,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 12,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 53,\n",
       " 4,\n",
       " 32,\n",
       " 98,\n",
       " 28,\n",
       " 29,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 18,\n",
       " 19,\n",
       " 26,\n",
       " 4,\n",
       " 13,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 44,\n",
       " 4,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 20,\n",
       " 33,\n",
       " 5,\n",
       " 15,\n",
       " 3,\n",
       " 22,\n",
       " 43,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 26,\n",
       " 12,\n",
       " 33,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 15,\n",
       " 16,\n",
       " 1,\n",
       " 14,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 45,\n",
       " 3,\n",
       " 10,\n",
       " 24,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 30,\n",
       " 6,\n",
       " 18,\n",
       " 4,\n",
       " 7,\n",
       " 23,\n",
       " 1,\n",
       " 17,\n",
       " 18,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 39,\n",
       " 20,\n",
       " 27,\n",
       " 6,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 56,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 2,\n",
       " 24,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 15,\n",
       " 1,\n",
       " 27,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 5,\n",
       " 15,\n",
       " 65,\n",
       " 23,\n",
       " 1,\n",
       " 73,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 117,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 13,\n",
       " 55,\n",
       " 26,\n",
       " 1,\n",
       " 14,\n",
       " 77,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 23,\n",
       " 10,\n",
       " 5,\n",
       " 1,\n",
       " 5,\n",
       " 11,\n",
       " 18,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 14,\n",
       " 4,\n",
       " 30,\n",
       " 1,\n",
       " 4,\n",
       " 16,\n",
       " 117,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 14,\n",
       " 6,\n",
       " 14,\n",
       " 12,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 2,\n",
       " 51,\n",
       " 11,\n",
       " 41,\n",
       " 13,\n",
       " 10,\n",
       " 1,\n",
       " 9,\n",
       " 37,\n",
       " 1,\n",
       " 1,\n",
       " 15,\n",
       " 78,\n",
       " 5,\n",
       " 1,\n",
       " 46,\n",
       " 38,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 30,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 35,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 12,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 148,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 19,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 30,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 61,\n",
       " 15,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 146,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 33,\n",
       " 1,\n",
       " 1,\n",
       " 42,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 11,\n",
       " 5,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 47,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 12,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 26,\n",
       " 8,\n",
       " 25,\n",
       " 1,\n",
       " 7,\n",
       " 17,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 79,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 11,\n",
       " 1,\n",
       " 1,\n",
       " 13,\n",
       " 2,\n",
       " 1,\n",
       " 30,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 34,\n",
       " 1,\n",
       " 153,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 48,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 37,\n",
       " 1,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 195,\n",
       " 1,\n",
       " 193,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 43,\n",
       " 25,\n",
       " 1,\n",
       " 1,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 22,\n",
       " 1,\n",
       " 1,\n",
       " 73,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 20,\n",
       " 65,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 113,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 20,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 30,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 14,\n",
       " 10,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 13,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 22,\n",
       " 19,\n",
       " 1,\n",
       " 9,\n",
       " 12,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 14,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 73,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 133,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 21,\n",
       " 40,\n",
       " 3,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 15,\n",
       " 1,\n",
       " 11,\n",
       " 46,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 34,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 56,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 17,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 26,\n",
       " 12,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 19,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 11,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 35,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 21,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 11,\n",
       " 1,\n",
       " 20,\n",
       " 1,\n",
       " 24,\n",
       " 1,\n",
       " 16,\n",
       " 1,\n",
       " 37,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 8,\n",
       " 3,\n",
       " 16,\n",
       " 1,\n",
       " 1,\n",
       " 44,\n",
       " 1,\n",
       " 1,\n",
       " 75,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 25,\n",
       " 10,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 19,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 41,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 14,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 11,\n",
       " 33,\n",
       " 5,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
