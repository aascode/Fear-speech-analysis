{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parent_path='../Data/New_Data_15-06-2020/'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import parmap\n",
    "import pandas as pd\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from utils.marking_similars import *\n",
    "from utils.preprocess import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_data=pd.read_csv(parent_path+'Data_text_spam_removed_v02.csv')\n",
    "temp=whatsapp_data[['group_id_anonymized','phone_num_anonymized','message_text','timestamp']]\n",
    "duplicateDFRow = temp[temp.duplicated()]\n",
    "whatsapp_data=whatsapp_data.drop(list(duplicateDFRow.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_to_consider = 0.8\n",
    "signature_obj=Signature(10)\n",
    "\n",
    "\n",
    "def remove_duplicates_within(sample_df):\n",
    "    sample_df=signature_obj.add_signatures(sample_df)\n",
    "    id_done=0\n",
    "    duplicate={}\n",
    "    row_repeated=[]\n",
    "    for index,row in tqdm(sample_df.iterrows(),total=len(sample_df)):\n",
    "        \n",
    "        id_done+=1\n",
    "        try:\n",
    "            temp_dupl=duplicate[index]\n",
    "            continue\n",
    "        except KeyError:\n",
    "            temp_repeated=row['repeated']\n",
    "            temp=sample_df[id_done:]\n",
    "            for index1,row1 in temp.iterrows():\n",
    "                try:\n",
    "                    temp_dupl=duplicate[index]\n",
    "                    continue\n",
    "                except KeyError:\n",
    "                    signature1=row['signatures']\n",
    "                    signature2=row1['signatures']\n",
    "                    count=0\n",
    "                    for k in range(0, signature_obj.numHashes):\n",
    "                        count = count + (signature1[k] == signature2[k])\n",
    "                    # add to tuple similar if greater than thresh    \n",
    "                    if((count/signature_obj.numHashes)>thresh_to_consider):\n",
    "                        duplicate[index1]=1\n",
    "                        temp_repeated+=row1['repeated']\n",
    "            temp_repeated=list(set(temp_repeated))\n",
    "            row_repeated.append(temp_repeated)\n",
    "    sample_df=sample_df.drop(list(duplicate.keys()))\n",
    "    sample_df['repeated']=row_repeated\n",
    "    return sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5338/5338 [00:10<00:00, 511.97it/s]\n",
      "  0%|          | 0/5338 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2552858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5338/5338 [14:43<00:00,  6.04it/s] \n"
     ]
    }
   ],
   "source": [
    "annotated_df=pd.read_pickle(parent_path+'Fearspeech_data.pkl')\n",
    "annotated_df=remove_duplicates_within(annotated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "countrepeat_list=[]\n",
    "count_missing=0\n",
    "for index,row in annotated_df.iterrows():\n",
    "    if(len(row['repeated'])>0):\n",
    "        countrepeat_list.append(len(row['repeated']))\n",
    "    else:\n",
    "        countrepeat_list.append(0)\n",
    "        count_missing+=1\n",
    "annotated_df['times_repeated']=countrepeat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df=annotated_df[annotated_df['times_repeated']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df.to_pickle(parent_path+'Fearspeech_data_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4782/4782 [00:00<00:00, 13298.67it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fear_speech_index=[]\n",
    "all_normal_index=[]\n",
    "\n",
    "count_fearspeech=0\n",
    "count_normal=0\n",
    "\n",
    "for index,row in tqdm(annotated_df.iterrows(),total=len(annotated_df)):\n",
    "    if(row['one_fear_speech']==1):\n",
    "        count_fearspeech+=1\n",
    "        all_fear_speech_index+=row['repeated']\n",
    "    elif(row['one_fear_speech']==0):\n",
    "        count_normal+=1\n",
    "        all_normal_index+=row['repeated']\n",
    "\n",
    "data_fear_speech=whatsapp_data[whatsapp_data['orig_index'].isin(all_fear_speech_index)]\n",
    "data_normal=whatsapp_data[whatsapp_data['orig_index'].isin(all_normal_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fear speech: 1142\n",
      "Normal: 3640\n"
     ]
    }
   ],
   "source": [
    "print(\"Fear speech:\",len(annotated_df[annotated_df['one_fear_speech']==1]))\n",
    "print(\"Normal:\",len(annotated_df[annotated_df['one_fear_speech']==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_stats(df,whatsapp_data):\n",
    "    df_groups=df.group_id_anonymized.unique()\n",
    "   \n",
    "    average_user_per_group= 0\n",
    "    for group in df_groups:\n",
    "        number_of_users=whatsapp_data[whatsapp_data['group_id_anonymized']==group].phone_num_anonymized.nunique()\n",
    "        average_user_per_group+=number_of_users\n",
    "    average_user_per_group/= len(df_groups)\n",
    "    \n",
    "    average_message_per_group= 0\n",
    "    for group in df_groups:\n",
    "        num_of_messages=len(whatsapp_data[whatsapp_data['group_id_anonymized']==group])\n",
    "        average_message_per_group+=num_of_messages\n",
    "    average_message_per_group/= len(df_groups)\n",
    "    \n",
    "    average_fear_user_per_group= 0\n",
    "    for group in df_groups:\n",
    "        number_of_users=df[df['group_id_anonymized']==group].phone_num_anonymized.nunique()\n",
    "        average_fear_user_per_group+=number_of_users\n",
    "    average_fear_user_per_group/= len(df_groups)\n",
    "    \n",
    "    average_fear_message_per_group= 0\n",
    "    for group in df_groups:\n",
    "        num_of_messages=len(df[df['group_id_anonymized']==group])\n",
    "        average_fear_message_per_group+=num_of_messages\n",
    "    average_fear_message_per_group/= len(df_groups)\n",
    "    \n",
    "    df_users=df.phone_num_anonymized.unique()\n",
    "    \n",
    "    avg_number_group_per_users=0\n",
    "    for user in df_users:\n",
    "        number_of_users=whatsapp_data[whatsapp_data['phone_num_anonymized']==user].group_id_anonymized.nunique()\n",
    "        avg_number_group_per_users+=number_of_users\n",
    "    avg_number_group_per_users/=len(df_users)\n",
    "    \n",
    "    \n",
    "    average_fear_message_per_user= 0\n",
    "    for user in df_users:\n",
    "        num_of_messages=len(df[df['phone_num_anonymized']==user])\n",
    "        average_fear_message_per_user+=num_of_messages\n",
    "    average_fear_message_per_user/= len(df_users)\n",
    "    \n",
    "    average_message_per_user= 0\n",
    "    for user in df_users:\n",
    "        num_of_messages=len(whatsapp_data[whatsapp_data['phone_num_anonymized']==user])\n",
    "        average_message_per_user+=num_of_messages\n",
    "    average_message_per_user/= len(df_users)\n",
    "\n",
    "    ###average message length in chars\n",
    "    sum1=0\n",
    "    for index,row in tqdm(df.iterrows(),total=df.shape[0]):\n",
    "        sum1+=len(preprocess_sent(row[\"message_text\"],params={'remove_numbers': True, 'remove_emoji': True, 'remove_stop_words': False, 'tokenize': True}))\n",
    "    average_message_length= sum1/len(df)\n",
    "        \n",
    "    \n",
    "    dict1={}\n",
    "    \n",
    "    dict1[\"Total message\"]=len(df)\n",
    "    dict1[\"Total unique message\"]=len(annotated_df[annotated_df['one_fear_speech']==1])\n",
    "    dict1[\"Total users having atleast one fear speech (Fear speech users)\"]=len(df_users)\n",
    "    dict1[\"Total groups having atleast one fear speeach (Fear speech groups)\"]=len(df_groups)\n",
    "    dict1[\"Total languages\"]=len(df.groupby('language'))\n",
    "    dict1[\"Average number of users in Fear speech group\"]=int(average_user_per_group)\n",
    "    dict1[\"Average number of message in Fear speech group\"]=int(average_message_per_group)\n",
    "    dict1[\"Average number of fear speech users  in Fear speech group\"]=int(average_fear_user_per_group)\n",
    "    dict1[\"Average number of fear speech in Fear speech group\"]=int(average_fear_message_per_group)\n",
    "    dict1[\"Average number of groups by Fear speech users\"]=int(avg_number_group_per_users)\n",
    "    dict1[\"Average number of fear messages by Fear speech users\"]=int(average_fear_message_per_user)\n",
    "    dict1[\"Average number of messages by Fear speech users\"]=int(average_message_per_user)\n",
    "    dict1[\"Average message length of fear speech messages\"]=int(average_message_length)\n",
    "    return dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7848/7848 [01:45<00:00, 74.17it/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Total message': 7848,\n",
       " 'Total unique message': 1142,\n",
       " 'Total users having atleast one fear speech (Fear speech users)': 2935,\n",
       " 'Total groups having atleast one fear speeach (Fear speech groups)': 950,\n",
       " 'Total languages': 4,\n",
       " 'Average number of users in Fear speech group': 89,\n",
       " 'Average number of message in Fear speech group': 1230,\n",
       " 'Average number of fear speech users  in Fear speech group': 4,\n",
       " 'Average number of fear speech in Fear speech group': 8,\n",
       " 'Average number of groups by Fear speech users': 1,\n",
       " 'Average number of fear messages by Fear speech users': 2,\n",
       " 'Average number of messages by Fear speech users': 138,\n",
       " 'Average message length of fear speech messages': 500}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_stats(data_fear_speech,whatsapp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
