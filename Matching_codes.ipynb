{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "parent_path='../Data/New_Data_15-06-2020/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_df=pd.read_pickle(parent_path+'Fearspeech_data_final.pkl')\n",
    "whatsapp_data=pd.read_csv(parent_path+'Data_text_spam_removed_v02_hi_en.csv')\n",
    "temp=whatsapp_data[['group_id_anonymized','phone_num_anonymized','message_text','timestamp']]\n",
    "duplicateDFRow = temp[temp.duplicated()]\n",
    "whatsapp_data=whatsapp_data.drop(list(duplicateDFRow.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "from langdetect import DetectorFactory\n",
    "import parmap\n",
    "\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def add_language(df):\n",
    "    language= []\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        try:\n",
    "            lang=detect(row[\"message_text\"])\n",
    "            language.append(lang)\n",
    "        except:\n",
    "            language.append('unk')\n",
    "\n",
    "    df[\"language\"] = language\n",
    "    return df\n",
    "\n",
    "n_process=30\n",
    "\n",
    "\n",
    "df_split = np.array_split(whatsapp_data, n_process)\n",
    "list_all = parmap.map(add_language, df_split,pm_processes=n_process,pm_pbar=True)\n",
    "whatsapp_data=pd.concat(list_all,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_data=whatsapp_data[whatsapp_data['language'].isin(['hi','en'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Match(df, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n",
    "        \n",
    "    \n",
    "    # Transform the propensity scores and caliper when caliper_method is \"logit\" or \"none\"\n",
    "    if caliper_method == \"logit\":\n",
    "        propensity = log(propensity/(1-propensity))\n",
    "        caliper = caliper*np.std(propensity)\n",
    "    elif caliper_method == \"none\":\n",
    "        caliper = 0\n",
    "    \n",
    "    # Code groups as 0 and 1\n",
    "    #groups = groups == np.unique(groups)\n",
    "    N = len(df)\n",
    "    N1 = df[df['treatment'] == 1].index; N2 =df[df['treatment'] == 0].index\n",
    "    g1, g2 = df.loc[N1]['pscore'],df.loc[N2]['pscore']\n",
    "    # Check if treatment groups got flipped - the smaller should correspond to N1/g1\n",
    "    if len(N1) > len(N2):\n",
    "       N1, N2, g1, g2 = N2, N1, g2, g1\n",
    "        \n",
    "        \n",
    "    # Randomly permute the smaller group to get order for matching\n",
    "    morder = np.random.permutation(N1)\n",
    "    matches = {}\n",
    "\n",
    "    \n",
    "    for m in morder:\n",
    "        dist = abs(g1[m] - g2)\n",
    "        if (dist.min() <= caliper) or not caliper:\n",
    "            matches[m] = dist.idxmin()    # Potential problem: check for ties\n",
    "            if not replace:\n",
    "                g2 = g2.drop(matches[m])\n",
    "    return (matches)\n",
    "\n",
    "def whichMatched(matches, data, many = False, unique = False):\n",
    "    ''' \n",
    "    Simple function to convert output of Matches to DataFrame of all matched observations\n",
    "    Inputs:\n",
    "    matches = output of Match\n",
    "    data = DataFrame of covariates\n",
    "    many = Boolean indicating if matching method is one-to-one or one-to-many\n",
    "    unique = Boolean indicating if duplicated individuals (ie controls matched to more than one case) should be removed\n",
    "    '''\n",
    "\n",
    "    tr = matches.keys()\n",
    "    if many:\n",
    "        ctrl = [m for matchset in matches.values() for m in matchset]\n",
    "    else:\n",
    "        ctrl = matches.values()\n",
    "    # need to remove duplicate rows, which may occur in matching with replacement\n",
    "    temp = pd.concat([data.loc[tr], data.loc[ctrl]])\n",
    "    if unique == True:\n",
    "        return temp.groupby(temp.index).first()\n",
    "    else:\n",
    "        return temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def convert(year,month,date):\n",
    "    return int(datetime(year, month, date, 0, 0, 0).timestamp()*1000)\n",
    "\n",
    "def convert_reverse(timestamp):\n",
    "    dt_object = datetime.fromtimestamp(timestamp/1000)\n",
    "    print(\"dt_object =\", dt_object)\n",
    "    return dt_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_reverse(1530948979856)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_data=whatsapp_data.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whatsapp_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4782/4782 [00:00<00:00, 14913.93it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fear_speech_index=[]\n",
    "all_normal_index=[]\n",
    "\n",
    "count_fearspeech=0\n",
    "count_normal=0\n",
    "\n",
    "for index,row in tqdm(annotated_df.iterrows(),total=len(annotated_df)):\n",
    "    if(row['one_fear_speech']==1):\n",
    "        count_fearspeech+=1\n",
    "        all_fear_speech_index+=row['repeated']\n",
    "    elif(row['one_fear_speech']==0):\n",
    "        count_normal+=1\n",
    "        all_normal_index+=row['repeated']\n",
    "\n",
    "data_fear_speech=whatsapp_data[whatsapp_data['orig_index'].isin(all_fear_speech_index)]\n",
    "data_normal=whatsapp_data[whatsapp_data['orig_index'].isin(all_normal_index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 303/109542 [00:03<21:49, 83.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-ad7a78c98751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mtimestamp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcount\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mtemp_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'timestamp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetween\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclusive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2891\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2893\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2945\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2947\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3358\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m         \"\"\"\n\u001b[0;32m-> 3360\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3361\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m         new_data = self._mgr.take(\n\u001b[0;32m-> 3348\u001b[0;31m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m         )\n\u001b[1;32m   3350\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"take\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1433\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m             \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         )\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/punyajoy_gpu/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "tuples_list=[]\n",
    "\n",
    "for user in tqdm(whatsapp_data.phone_num_anonymized.unique(),total=whatsapp_data.phone_num_anonymized.nunique()):\n",
    "    temp={}\n",
    "    temp['user_id']=user\n",
    "    user_data=whatsapp_data[whatsapp_data['phone_num_anonymized']==user]\n",
    "    if(user in set(data_fear_speech.phone_num_anonymized.unique())):\n",
    "        temp['treatment']=1\n",
    "    else:\n",
    "        temp['treatment']=0\n",
    "        \n",
    "   \n",
    "    temp['num_groups']=user_data['group_id_anonymized'].nunique()\n",
    "    count=0\n",
    "    list_message_present=[]\n",
    "    for year in [2018,2019]:\n",
    "        for month in range(1,13):\n",
    "            timestamp=convert(year,month,1)\n",
    "            count+=1\n",
    "            temp_data=user_data[user_data['timestamp'].between(timestamp, timestamp+30*24*60*60*1000, inclusive=True)]\n",
    "            if(len(temp_data)>0):\n",
    "                try:\n",
    "                    start=temp['start_date']\n",
    "                except KeyError:\n",
    "                    temp['start_date']=count\n",
    "                list_message_present.append(len(temp_data))\n",
    "    if(len(list_message_present)>0):\n",
    "        temp['mean_messages']=np.mean(list_message_present)\n",
    "        temp['stdev_messages']=np.std(list_message_present)\n",
    "        temp['month_present']=len(list_message_present)\n",
    "        tuples_list.append(temp)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tuples_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>start_date</th>\n",
       "      <th>mean_messages</th>\n",
       "      <th>stdev_messages</th>\n",
       "      <th>month_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2148</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>7</td>\n",
       "      <td>24.571429</td>\n",
       "      <td>21.181914</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>247483</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.632993</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1287</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3.399346</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244632</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.674235</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>242857</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>24.115463</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108692</th>\n",
       "      <td>23730</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108693</th>\n",
       "      <td>174891</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108694</th>\n",
       "      <td>174892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108695</th>\n",
       "      <td>174080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108696</th>\n",
       "      <td>174900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108697 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  treatment  num_groups  start_date  mean_messages  \\\n",
       "0          2148          0         154           7      24.571429   \n",
       "1        247483          0           1           7      10.000000   \n",
       "2          1287          1           1           7       4.333333   \n",
       "3        244632          0           2           7       5.000000   \n",
       "4        242857          0           1           7      32.333333   \n",
       "...         ...        ...         ...         ...            ...   \n",
       "108692    23730          0           1          20       1.000000   \n",
       "108693   174891          0           1          20       1.000000   \n",
       "108694   174892          0           1          20      20.000000   \n",
       "108695   174080          0           1          20       1.000000   \n",
       "108696   174900          0           1          20       1.000000   \n",
       "\n",
       "        stdev_messages  month_present  \n",
       "0            21.181914             14  \n",
       "1             1.632993              3  \n",
       "2             3.399346              3  \n",
       "3             3.674235              4  \n",
       "4            24.115463              3  \n",
       "...                ...            ...  \n",
       "108692        0.000000              1  \n",
       "108693        0.000000              1  \n",
       "108694        0.000000              1  \n",
       "108695        0.000000              1  \n",
       "108696        0.000000              1  \n",
       "\n",
       "[108697 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pscore_match.pscore import PropensityScore\n",
    "#from pscore_match.match import Match, whichMatched\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "treatment = np.array(df.treatment)\n",
    "cov_list = ['num_groups','start_date','mean_messages','stdev_messages','month_present']\n",
    "#cov_list = ['start_date','month_present']\n",
    "\n",
    "covariates = df[cov_list]\n",
    "\n",
    "pscore = PropensityScore(treatment, covariates).compute()\n",
    "df['pscore']=pscore\n",
    "pairs = Match(df,caliper = 0.05)\n",
    "data_matched=whichMatched(pairs, df,many = False, unique = False)\n",
    "# pairs = Match(treatment, pscore)\n",
    "# pairs.create(method='one-to-one',caliper=0.001,replace=False)\n",
    "# data_matched = whichMatched(pairs, pd.DataFrame({'pscore': pscore, 'treatment' :treatment, 'user_id':df.user_id}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment=np.array(data_matched[data_matched['treatment']==1].pscore)\n",
    "control=np.array(data_matched[data_matched['treatment']==0].pscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2933"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fear_speech.phone_num_anonymized.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics=4298233.000, p=0.500\n",
      "Same distribution (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import mannwhitneyu\n",
    "# seed the random number generator\n",
    "seed(1)\n",
    "# generate two independent samples\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(treatment, control)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2932.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_matched)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_groups=[]\n",
    "for index,row in data_matched.iterrows():\n",
    "    if(row['treatment']==1):\n",
    "        matched_groups.append([int(row['user_id']),'Fear speech'])\n",
    "    else:\n",
    "        matched_groups.append([int(row['user_id']),'Non fear speech'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>treatment</th>\n",
       "      <th>num_groups</th>\n",
       "      <th>start_date</th>\n",
       "      <th>mean_messages</th>\n",
       "      <th>stdev_messages</th>\n",
       "      <th>month_present</th>\n",
       "      <th>pscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93971</th>\n",
       "      <td>219636</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>3</td>\n",
       "      <td>0.048243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5874</th>\n",
       "      <td>237650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>10.000</td>\n",
       "      <td>4.949747</td>\n",
       "      <td>4</td>\n",
       "      <td>0.031172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82294</th>\n",
       "      <td>177266</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>4.000</td>\n",
       "      <td>1.632993</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>26029</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7.375</td>\n",
       "      <td>4.820205</td>\n",
       "      <td>8</td>\n",
       "      <td>0.184425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84460</th>\n",
       "      <td>179003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2.250</td>\n",
       "      <td>1.639360</td>\n",
       "      <td>4</td>\n",
       "      <td>0.072255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94057</th>\n",
       "      <td>144207</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>4.500</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.028946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25930</th>\n",
       "      <td>67132</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.829156</td>\n",
       "      <td>4</td>\n",
       "      <td>0.049133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13588</th>\n",
       "      <td>151715</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6.625</td>\n",
       "      <td>2.735759</td>\n",
       "      <td>8</td>\n",
       "      <td>0.276065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10535</th>\n",
       "      <td>94013</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2.875</td>\n",
       "      <td>2.204399</td>\n",
       "      <td>8</td>\n",
       "      <td>0.225246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31189</th>\n",
       "      <td>125409</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>5.600</td>\n",
       "      <td>8.212186</td>\n",
       "      <td>5</td>\n",
       "      <td>0.087477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5864 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  treatment  num_groups  start_date  mean_messages  \\\n",
       "93971   219636          1           1          17          2.000   \n",
       "5874    237650          1           1           9         10.000   \n",
       "82294   177266          1           1          16          4.000   \n",
       "557      26029          1           1           7          7.375   \n",
       "84460   179003          1           1          16          2.250   \n",
       "...        ...        ...         ...         ...            ...   \n",
       "94057   144207          0           1          17          4.500   \n",
       "25930    67132          0           1          13          1.750   \n",
       "13588   151715          0           1          11          6.625   \n",
       "10535    94013          0           3          10          2.875   \n",
       "31189   125409          0           1          13          5.600   \n",
       "\n",
       "       stdev_messages  month_present    pscore  \n",
       "93971        0.816497              3  0.048243  \n",
       "5874         4.949747              4  0.031172  \n",
       "82294        1.632993              3  0.043026  \n",
       "557          4.820205              8  0.184425  \n",
       "84460        1.639360              4  0.072255  \n",
       "...               ...            ...       ...  \n",
       "94057        3.500000              2  0.028946  \n",
       "25930        0.829156              4  0.049133  \n",
       "13588        2.735759              8  0.276065  \n",
       "10535        2.204399              8  0.225246  \n",
       "31189        8.212186              5  0.087477  \n",
       "\n",
       "[5864 rows x 8 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_matched=pd.DataFrame(matched_groups,columns=['user_id','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_matched.to_csv(parent_path+'final_user_selection_matched.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219636</td>\n",
       "      <td>Fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>237650</td>\n",
       "      <td>Fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>177266</td>\n",
       "      <td>Fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26029</td>\n",
       "      <td>Fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179003</td>\n",
       "      <td>Fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>144207</td>\n",
       "      <td>Non fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>67132</td>\n",
       "      <td>Non fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5861</th>\n",
       "      <td>151715</td>\n",
       "      <td>Non fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>94013</td>\n",
       "      <td>Non fear speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5863</th>\n",
       "      <td>125409</td>\n",
       "      <td>Non fear speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5864 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id       annotation\n",
       "0      219636      Fear speech\n",
       "1      237650      Fear speech\n",
       "2      177266      Fear speech\n",
       "3       26029      Fear speech\n",
       "4      179003      Fear speech\n",
       "...       ...              ...\n",
       "5859   144207  Non fear speech\n",
       "5860    67132  Non fear speech\n",
       "5861   151715  Non fear speech\n",
       "5862    94013  Non fear speech\n",
       "5863   125409  Non fear speech\n",
       "\n",
       "[5864 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_group_matched"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict \n",
    "group_dict={}\n",
    "for group in data_fear_speech.group_id_anonymized.unique():\n",
    "    temp=data_fear_speech[data_fear_speech['group_id_anonymized']==group]\n",
    "    group_dict[group]=len(temp)\n",
    "dict1 = sorted(group_dict.items(),key=lambda item: item[1],reverse=True)\n",
    "\n",
    "selected_groups=[ele[0] for ele in dict1[0:100]]\n",
    "len(selected_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tuples_list_grp=[]\n",
    "\n",
    "for user in tqdm_notebook(whatsapp_data.group_id_anonymized.unique(),total=whatsapp_data.group_id_anonymized.nunique()):\n",
    "    temp={}\n",
    "    temp['group_id']=user\n",
    "    user_data=whatsapp_data[whatsapp_data['group_id_anonymized']==user]\n",
    "    if(user in data_fear_speech.group_id_anonymized.unique()):\n",
    "        if(user in selected_groups):\n",
    "            temp['treatment']=1\n",
    "        else:\n",
    "            temp['treatment']=-1\n",
    "    else:\n",
    "        temp['treatment']=0\n",
    "        \n",
    "   \n",
    "    temp['num_users']=user_data['phone_num_anonymized'].nunique()\n",
    "    count=0\n",
    "    list_message_present=[]\n",
    "    for year in [2018,2019]:\n",
    "        for month in range(1,13):\n",
    "            timestamp=convert(year,month,1)\n",
    "            count+=1\n",
    "            temp_data=user_data[user_data['timestamp'].between(timestamp, timestamp+30*24*60*60*1000, inclusive=True)]\n",
    "            if(len(temp_data)>0):\n",
    "                try:\n",
    "                    start=temp['start_date']\n",
    "                except KeyError:\n",
    "                    temp['start_date']=count\n",
    "                list_message_present.append(len(temp_data))\n",
    "    if(len(list_message_present)>0):\n",
    "        temp['mean_messages']= len(user_data)/temp['num_users']\n",
    "        temp['stdev_messages']=np.std(list_message_present)\n",
    "        temp['month_present']=len(list_message_present)\n",
    "        tuples_list_grp.append(temp)         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = pd.DataFrame(tuples_list_grp) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = df_groups[df_groups['treatment']!=-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_groups[df_groups['treatment']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pscore_match.pscore import PropensityScore\n",
    "#from pscore_match.match import Match, whichMatched\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "treatment = np.array(df_groups.treatment)\n",
    "cov_list = ['start_date','num_users','month_present','mean_messages']\n",
    "#cov_list = ['start_date','month_present']\n",
    "\n",
    "covariates = df_groups[cov_list]\n",
    "\n",
    "pscore = PropensityScore(treatment, covariates).compute()\n",
    "df_groups['pscore']=pscore\n",
    "pairs = Match(df_groups,caliper = 0.1)\n",
    "data_matched=whichMatched(pairs, df_groups, many = False, unique = False)\n",
    "# pairs = Match(treatment, pscore)\n",
    "# pairs.create(method='one-to-one',caliper=0.001,replace=False)\n",
    "# data_matched = whichMatched(pairs, pd.DataFrame({'pscore': pscore, 'treatment' :treatment, 'user_id':df.user_id}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment=np.array(data_matched[data_matched['treatment']==1].pscore)\n",
    "control=np.array(data_matched[data_matched['treatment']==0].pscore)\n",
    "\n",
    "\n",
    "#print(data_fear_speech.group_id_anonymized.nunique())\n",
    "print(len(treatment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "# seed random number generator\n",
    "seed(1)\n",
    "# prepare data\n",
    "data1 = 20 * randn(1000) + 100\n",
    "data2 = data1 + (10 * randn(1000) + 50)\n",
    "# calculate Pearson's correlation\n",
    "corr, _ = pearsonr(df_groups['start_date'], df_groups['month_present'])\n",
    "print('Pearsons correlation: %.3f' % corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import mannwhitneyu\n",
    "# seed the random number generator\n",
    "seed(2)\n",
    "# generate two independent samples\n",
    "# compare samples\n",
    "stat, p = mannwhitneyu(treatment, control)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpret\n",
    "alpha = 0.005\n",
    "if p > alpha:\n",
    "\tprint('Same distribution (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different distribution (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fear_speech_groups=data_matched[data_matched['treatment']==1]['group_id']\n",
    "non_fear_speech_groups=data_matched[data_matched['treatment']==0]['group_id']\n",
    "\n",
    "\n",
    "fear_speech_groups_user=list(whatsapp_data[whatsapp_data['group_id_anonymized'].isin(fear_speech_groups)].phone_num_anonymized.unique())\n",
    "non_fear_speech_groups_user=list(whatsapp_data[whatsapp_data['group_id_anonymized'].isin(non_fear_speech_groups)].phone_num_anonymized.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_users=set(non_fear_speech_groups_user).intersection(set(fear_speech_groups_user))\n",
    "fear_speech_groups_user=set(fear_speech_groups_user).difference(common_users)\n",
    "non_fear_speech_groups_user=set(non_fear_speech_groups_user).difference(common_users)\n",
    "\n",
    "fear_speech_groups_user=fear_speech_groups_user.difference(set(data_fear_speech.phone_num_anonymized.unique()))\n",
    "non_fear_speech_groups_user=non_fear_speech_groups_user.difference(set(data_fear_speech.phone_num_anonymized.unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(fear_speech_groups_user),len(non_fear_speech_groups_user),len(data_fear_speech.phone_num_anonymized.unique()))\n",
    "\n",
    "\n",
    "\n",
    "tuple_list=[]\n",
    "\n",
    "for ele in fear_speech_groups_user:\n",
    "    tuple_list.append([ele,'in_FS_group'])\n",
    "for ele in non_fear_speech_groups_user:\n",
    "    tuple_list.append([ele,'in_NFS_group'])\n",
    "for ele in data_fear_speech.phone_num_anonymized.unique():\n",
    "    tuple_list.append([ele,'FS_user'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_survey=pd.DataFrame(tuple_list,columns=['user_id','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_survey.to_csv('users_for_survey.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users_survey.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_data.phone_num_anonymized.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_groups=[]\n",
    "for index,row in data_matched.iterrows():\n",
    "    if(row['treatment']==1):\n",
    "        matched_groups.append([int(row['group_id']),'Fear speech'])\n",
    "    else:\n",
    "        matched_groups.append([int(row['group_id']),'Non fear speech'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_matched=pd.DataFrame(matched_groups,columns=['grp_id','annotation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_matched.to_csv(parent_path+'final_group_selection_matched.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(treatment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-punyajoy_gpu] *",
   "language": "python",
   "name": "conda-env-.conda-punyajoy_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
